{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用printf调试代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 63\u001b[0m\n\u001b[1;32m     59\u001b[0m output_mat_gpu \u001b[39m=\u001b[39m gpuarray\u001b[39m.\u001b[39mempty_like(test_a_gpu)\n\u001b[1;32m     61\u001b[0m matrix_ker(test_a_gpu, test_b_gpu, output_mat_gpu, np\u001b[39m.\u001b[39mint32(\u001b[39m4\u001b[39m), block\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m), grid\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m))\n\u001b[0;32m---> 63\u001b[0m \u001b[39massert\u001b[39;00m( np\u001b[39m.\u001b[39mallclose(output_mat_gpu\u001b[39m.\u001b[39mget(), output_mat) )\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pycuda.autoinit\n",
    "import pycuda.driver as drv\n",
    "from pycuda import gpuarray\n",
    "from pycuda.compiler import SourceModule\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "ker = SourceModule('''\n",
    "// row-column dot-product for matrix multiplication\n",
    "__device__ float rowcol_dot(float *matrix_a, float *matrix_b, int row, int col, int N)\n",
    "{\n",
    "    // printf(\"threadIdx.x,y: %d,%d blockIdx.x,y: %d,%d -- row is %d, col is %d, N is %d.\\\\n\", threadIdx.x, threadIdx.y, blockIdx.x, blockIdx.y, row, col, N);\n",
    "\tfloat val = 0;\n",
    "\t\n",
    "\tfor (int k=0; k < N; k++)\n",
    "\t{\n",
    "    \n",
    "        // broken version\n",
    "        val += matrix_a[ row + k*N ] * matrix_b[ col*N + k];\n",
    "        // if(threadIdx.x == 0 && threadIdx.y == 0 && blockIdx.x == 0 && blockIdx.y == 0)\n",
    "        //    printf(\"Dot-product loop: k value is %d, matrix_a value is %f, matrix_b is %f.\\\\n\", k, matrix_a[ row + k*N ], matrix_b[ col*N + k]);\n",
    "\t\t\n",
    "        // fixed version\n",
    "        // val += matrix_a[ row*N + k ] * matrix_b[ col + k*N];\n",
    "\t}\n",
    "\t\n",
    "\treturn(val);\n",
    "}\n",
    "// matrix multiplication kernel that is parallelized over row/column tuples.\n",
    "__global__ void matrix_mult_ker(float * matrix_a, float * matrix_b, float * output_matrix, int N)\n",
    "{\n",
    "   // broken version\n",
    "    int row = blockIdx.x + threadIdx.x;\n",
    "\tint col = blockIdx.y + threadIdx.y;\n",
    "    \n",
    "    // fixed version\n",
    "    // int row = blockIdx.x*blockDim.x + threadIdx.x;\n",
    "    // int col = blockIdx.y*blockDim.y + threadIdx.y;\n",
    "    \n",
    "    // printf(\"threadIdx.x,y: %d,%d blockIdx.x,y: %d,%d -- row is %d, col is %d.\\\\n\", threadIdx.x, threadIdx.y, blockIdx.x, blockIdx.y, row, col);\n",
    "\t\n",
    "    // broken version\n",
    "    output_matrix[col + row*N] = rowcol_dot(matrix_a, matrix_b, col, row, N);\n",
    "    \n",
    "    // fixed version\n",
    "\t// output_matrix[col + row*N] = rowcol_dot(matrix_a, matrix_b, row, col, N);\n",
    "}\n",
    "''')\n",
    "\n",
    "matrix_ker = ker.get_function('matrix_mult_ker')\n",
    "\n",
    "test_a = np.float32( [range(1,5)] * 4 )\n",
    "test_b = np.float32([range(14,10, -1)]*4 )\n",
    "\n",
    "output_mat = np.matmul(test_a, test_b)\n",
    "\n",
    "test_a_gpu = gpuarray.to_gpu(test_a)\n",
    "test_b_gpu = gpuarray.to_gpu(test_b)\n",
    "output_mat_gpu = gpuarray.empty_like(test_a_gpu)\n",
    "\n",
    "matrix_ker(test_a_gpu, test_b_gpu, output_mat_gpu, np.int32(4), block=(2,2,1), grid=(2,2,1))\n",
    "\n",
    "assert( np.allclose(output_mat_gpu.get(), output_mat) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "33982229682c888955ca524121202fe70bc1f8616e2a0962e61b4bee7840fbc6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
